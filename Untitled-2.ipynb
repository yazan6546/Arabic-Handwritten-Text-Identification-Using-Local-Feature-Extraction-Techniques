{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction and Transformation Pipeline\n",
    "\n",
    "This notebook demonstrates the process of feature extraction, clustering, histogram creation, and IDF computation using custom transformers and pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from classes.feature_extractor import FeatureExtractor\n",
    "from classes.clusterer import Clusterer\n",
    "from utilities import utils, process, modify, evaluate\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "Load images, create a DataFrame, encode labels, and split the data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = utils.load_images_to_dataframe('data/preprocessed')\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "df['Target'] = label_encoder.fit_transform(df['Target'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the optimal kmeans clusters number\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Clusterer.find_best_cluster_number(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform the Data and Add Histograms to DataFrame\n",
    "\n",
    "Use the pipelines to fit and transform the training data, and add the resulting histograms back into the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first histogram to verify\n",
    "if not train_df.empty:\n",
    "    first_user = train_df.index[1]\n",
    "    first_histogram = train_df.iloc[1]['histogram_ORB_IDF']\n",
    "    plt.bar(range(100), first_histogram)\n",
    "    plt.title(f'Visual Words Histogram for User: {first_user}')\n",
    "    plt.xlabel('Visual Word Index')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_images(df):\n",
    "    if 'image' not in df.columns:\n",
    "        raise KeyError(\"The DataFrame does not contain an 'image' column.\")\n",
    "    return df['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Create Pipelines\n",
    "# -----------------------------\n",
    "# Pipeline for ORB Features with SVM Classifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "pipeline_ORB_SVM = Pipeline([\n",
    "    ('extract_images', FunctionTransformer(utils.extract_images, validate=False)),\n",
    "    ('feature_extractor', FeatureExtractor(method='ORB')),\n",
    "    ('clusterer', Clusterer(num_clusters=500)),\n",
    "    # ('idf_transformer', IDFTransformer()),\n",
    "    ('classifier', SVC(class_weight='balanced', C=50, random_state=0, gamma=0.001, degree=2))\n",
    "])\n",
    "\n",
    "# Pipeline for SIFT Features with SVM Classifier\n",
    "pipeline_SIFT_SVM = Pipeline([\n",
    "    ('extract_images', FunctionTransformer(utils.extract_images, validate=False)),\n",
    "    ('feature_extractor', FeatureExtractor(method='SIFT')),\n",
    "    ('clusterer', Clusterer(num_clusters=500)),\n",
    "    # ('idf_transformer', IDFTransformer()),\n",
    "    ('classifier', SVC(class_weight='balanced', C=50, random_state=0, gamma=0.001, degree=2))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the pipelines on the training data\n",
    "pipeline_ORB_SVM.fit(train_df, train_df['Target'])\n",
    "# pipeline_SIFT_SVM.fit(train_df, train_df['Target'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_SIFT_SVM.fit(train_df, train_df['Target'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(pipeline_ORB_SVM, 'models/pipeline_ORB_SVM_500.joblib')\n",
    "# joblib.dump(pipeline_ORB_SVM, 'models/pipeline_SIFT_SVM_500.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_ORB_SVM=joblib.load('models/pipeline_ORB_SVM_500.joblib')\n",
    "# pipeline_SIFT_SVM=joblib.load('models/pipeline_SIFT_SVM_500.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_df = evaluate.evaluate_models(pipeline_ORB_SVM, pipeline_SIFT_SVM, test_df)\n",
    "accuracy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in list(test_df['Target'].values):\n",
    "    if type(x) is not np.int64:\n",
    "        print(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Define Parameter Grid for GridSearchCV\n",
    "# -----------------------------\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'clusterer__num_clusters': [200, 300, 400, 500, 600, 700, 800]\n",
    "}\n",
    "\n",
    "# -----------------------------\n",
    "# Initialize GridSearchCV for ORB Pipeline\n",
    "# -----------------------------\n",
    "grid_search_ORB = GridSearchCV(\n",
    "    estimator=pipeline_ORB_SVM,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Fit GridSearchCV for ORB Pipeline\n",
    "# -----------------------------\n",
    "from sklearn.metrics import classification_report, accuracy_score  # This is correct\n",
    "\n",
    "\n",
    "print(\"Starting GridSearchCV for ORB Pipeline...\")\n",
    "grid_search_ORB.fit(train_df, train_df['Target'])\n",
    "print(\"GridSearchCV for ORB Pipeline completed.\\n\")\n",
    "\n",
    "# -----------------------------\n",
    "# Best Parameters and Score for ORB\n",
    "# -----------------------------\n",
    "print(\"Best Parameters for ORB Pipeline:\", grid_search_ORB.best_params_)\n",
    "print(\"Best Cross-Validation Accuracy for ORB Pipeline:\", grid_search_ORB.best_score_)\n",
    "\n",
    "# -----------------------------\n",
    "# Predict and Evaluate ORB Pipeline\n",
    "# -----------------------------\n",
    "best_ORB = grid_search_ORB.best_estimator_\n",
    "predictions_ORB = best_ORB.predict(test_df['histogram_ORB_IDF'])\n",
    "\n",
    "print(\"\\nORB SVM Classification Report:\")\n",
    "print(classification_report(test_df['Target'], predictions_ORB))\n",
    "print(\"ORB SVM Accuracy:\", accuracy_score(test_df['Target'], predictions_ORB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_ORB.best_estimator_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
